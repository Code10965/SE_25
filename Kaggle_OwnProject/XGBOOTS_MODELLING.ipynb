{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "municipal-cambodia",
   "metadata": {},
   "source": [
    "# MODELLING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "still-miniature",
   "metadata": {
    "hide_input": false
   },
   "outputs": [],
   "source": [
    "# general sys modules / libraries\n",
    "import sys\n",
    "import warnings  \n",
    "warnings.filterwarnings('ignore') \n",
    "\n",
    "# data analysis and visualisation modules / libraries\n",
    "import numpy as np\n",
    "from numpy import loadtxt\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as mtick\n",
    "from matplotlib.ticker import PercentFormatter\n",
    "\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "import scipy.stats as scs\n",
    "from scipy import stats\n",
    "\n",
    "# machine learning modules / libraries\n",
    "import xgboost as xgb\n",
    "from xgboost import plot_importance\n",
    "from xgboost import XGBClassifier\n",
    "from xgboost import XGBRegressor\n",
    "\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "\n",
    "import sklearn\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "covered-grass",
   "metadata": {
    "hide_input": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Read dataset\n",
    "data = 'datasets/train_model.csv'\n",
    "train_model= pd.read_csv(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "greenhouse-figure",
   "metadata": {
    "hide_input": true
   },
   "source": [
    "# Finetuning of the Hyper Parameters\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "surprised-shareware",
   "metadata": {
    "hide_input": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: You are using pip version 21.0.1; however, version 21.1 is available.\r\n",
      "You should consider upgrading via the '/Library/Frameworks/Python.framework/Versions/3.9/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\r\n"
     ]
    }
   ],
   "source": [
    "!pip -q install shap\n",
    "import shap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "eastern-associate",
   "metadata": {
    "hide_input": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import xgboost\n",
    "import shap\n",
    "\n",
    "dataset = train_model\n",
    "# training an XGBoost model\n",
    "X = train_model.drop(['target'], axis=1)\n",
    "y = train_model['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "clear-gamma",
   "metadata": {},
   "outputs": [],
   "source": [
    "os = RandomOverSampler(sampling_strategy=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "academic-academy",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train = os.fit_resample(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "charitable-trustee",
   "metadata": {
    "hide_input": false
   },
   "outputs": [],
   "source": [
    "# splitting data into train and test sets\n",
    "seed = 7\n",
    "test_size = 0.33\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, random_state=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "consistent-legislature",
   "metadata": {
    "hide_input": false
   },
   "outputs": [],
   "source": [
    "# finetuning the hyper parameters of xgboost \n",
    "def hyperParameterTuning(X_train, y_train):\n",
    "    param_tuning = {\n",
    "        'learning_rate': [0.01, 0.1, 0.3],\n",
    "        'max_depth': [3, 5, 7, 10],\n",
    "        'min_child_weight': [1, 3, 5]\n",
    "    }\n",
    "\n",
    "    xgb_model = XGBRegressor()\n",
    "\n",
    "    parameter_search = GridSearchCV(estimator = xgb_model,\n",
    "                           param_grid = param_tuning,                        \n",
    "                           cv = 5,\n",
    "                           n_jobs = -1,\n",
    "                           verbose = 1)\n",
    "\n",
    "    parameter_search.fit(X_train,y_train)\n",
    "\n",
    "    return parameter_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cross-austin",
   "metadata": {
    "hide_input": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 36 candidates, totalling 180 fits\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'learning_rate': 0.1, 'max_depth': 3, 'min_child_weight': 3}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# To start the tuning remove the '#' in the next line // ATTENTION: the calculation can take a few minutes\n",
    "hyperParameterTuning(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efficient-closing",
   "metadata": {},
   "source": [
    "OUTCOME OF Hyper Parameter Tuning: 'learning_rate': 0.1, 'max_depth': 3, 'min_child_weight': 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "instrumental-malta",
   "metadata": {
    "hide_input": false
   },
   "outputs": [],
   "source": [
    "# fit model to training data\n",
    "def show_model():\n",
    "    model = XGBClassifier(learning_rate=0.1, max_depth= 3, min_child_weight= 3).fit(X_train, y_train)\n",
    "    print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "boring-romantic",
   "metadata": {
    "hide_input": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17:24:44] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
      "              colsample_bynode=1, colsample_bytree=1, gamma=0, gpu_id=-1,\n",
      "              importance_type='gain', interaction_constraints='',\n",
      "              learning_rate=0.1, max_delta_step=0, max_depth=3,\n",
      "              min_child_weight=3, missing=nan, monotone_constraints='()',\n",
      "              n_estimators=100, n_jobs=8, num_parallel_tree=1, random_state=0,\n",
      "              reg_alpha=0, reg_lambda=1, scale_pos_weight=1, subsample=1,\n",
      "              tree_method='exact', validate_parameters=1, verbosity=None)\n"
     ]
    }
   ],
   "source": [
    "show_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "going-english",
   "metadata": {
    "hide_input": true
   },
   "source": [
    "# Evaluation of the Model\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "falling-crisis",
   "metadata": {
    "hide_input": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17:24:44] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    }
   ],
   "source": [
    "model = XGBClassifier(learning_rate=0.1, max_depth= 3, min_child_weight= 3).fit(X_train, y_train)\n",
    "# make predictions for test data\n",
    "y_pred = model.predict(X_test)\n",
    "predictions = [round(value) for value in y_pred]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "opened-match",
   "metadata": {
    "hide_input": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 78.77%\n"
     ]
    }
   ],
   "source": [
    "# evaluate predictions\n",
    "accuracy = accuracy_score(y_test, predictions)\n",
    "print(\"Accuracy: %.2f%%\" % (accuracy * 100.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "superb-bennett",
   "metadata": {
    "hide_input": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17:24:45] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[17:24:46] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[17:24:46] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[17:24:47] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[17:24:47] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[17:24:48] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[17:24:48] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[17:24:49] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[17:24:50] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[17:24:51] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[17:24:52] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Performance (mean) in Train</th>\n",
       "      <th>Performance (std) in  Train</th>\n",
       "      <th>Performance (mean) in Test</th>\n",
       "      <th>Performance (std) in  Test</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Model</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>XGB_tuned</th>\n",
       "      <td>0.807025</td>\n",
       "      <td>0.002166</td>\n",
       "      <td>0.797435</td>\n",
       "      <td>0.005753</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>XGB_standard</th>\n",
       "      <td>0.876624</td>\n",
       "      <td>0.001601</td>\n",
       "      <td>0.788997</td>\n",
       "      <td>0.005075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Random_Model</th>\n",
       "      <td>0.627220</td>\n",
       "      <td>0.001957</td>\n",
       "      <td>0.636172</td>\n",
       "      <td>0.009061</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Performance (mean) in Train  Performance (std) in  Train  \\\n",
       "Model                                                                    \n",
       "XGB_tuned                        0.807025                     0.002166   \n",
       "XGB_standard                     0.876624                     0.001601   \n",
       "Random_Model                     0.627220                     0.001957   \n",
       "\n",
       "              Performance (mean) in Test  Performance (std) in  Test  \n",
       "Model                                                                 \n",
       "XGB_tuned                       0.797435                    0.005753  \n",
       "XGB_standard                    0.788997                    0.005075  \n",
       "Random_Model                    0.636172                    0.009061  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "XGB = XGBClassifier(\n",
    "                learning_rate=0.1, \n",
    "                max_depth=3,\n",
    "                min_child_weight=3\n",
    "                ).fit(X_train, y_train)\n",
    "\n",
    "def append_modell_performance(performance, model_name, classifier, X_train, y_train, cv=5):\n",
    "\n",
    "    # Calculate cross-validation mean performance scores\n",
    "    cv_scores = cross_validate(classifier, X_train, y_train, cv=cv, return_train_score=True)\n",
    "\n",
    "    # Append performance dictionary with \n",
    "    performance = performance.append({\n",
    "                            'Model': model_name,\n",
    "                            'Performance (mean) in Train': cv_scores['train_score'].mean(),\n",
    "                            'Performance (std) in  Train': cv_scores['train_score'].std(),\n",
    "                            'Performance (mean) in Test': cv_scores['test_score'].mean(),\n",
    "                            'Performance (std) in  Test': cv_scores['test_score'].std()\n",
    "                            }, ignore_index=True)\n",
    "    return performance\n",
    "\n",
    "# Create performance overview\n",
    "performance_table = pd.DataFrame(columns=['Model', 'Performance (mean) in Train','Performance (std) in  Train', 'Performance (mean) in Test','Performance (std) in  Test'])\n",
    "    \n",
    "# Define XGBoost and benchmark models\n",
    "models = [\n",
    "        {\n",
    "        'name': 'XGB_tuned',\n",
    "        'model': XGB,\n",
    "        },\n",
    "        {\n",
    "        'name': 'XGB_standard',\n",
    "        'model': XGBClassifier(),\n",
    "        },\n",
    "        {\n",
    "        'name': 'Random_Model',\n",
    "        'model': DummyClassifier(strategy='stratified'),\n",
    "        }]\n",
    " \n",
    "for model in models:\n",
    "    performance_table = append_modell_performance(performance_table, \n",
    "                                                model['name'], \n",
    "                                                model['model'], \n",
    "                                                X, y)\n",
    "\n",
    "# Get an ordered table summarizing the model performances   \n",
    "performance_table = performance_table.set_index('Model') \n",
    "performance_table.sort_values(by='Performance (mean) in Test', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "supposed-smooth",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "oldHeight": 201,
   "position": {
    "height": "223px",
    "left": "789px",
    "right": "20px",
    "top": "130px",
    "width": "563px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "varInspector_section_display": "block",
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
